# Potential Bugs and Suspicious Logic

## 1. Projectile rehydration drops remaining travel distance
- **File(s):** `server/effects.go`, `server/effects_manager.go`
- **Code:** `spawnContractProjectileFromInstance` rebuilds a projectile effect from an `EffectInstance`, and `syncProjectileInstance` stores runtime values in `BehaviorState.Extra` / `Params` (including `remainingRange`).
- **Why it’s a problem:** When the server needs to recreate a projectile (e.g. after a resync hint or effect lookup miss), `spawnContractProjectileFromInstance` ignores the persisted `remainingRange` value. It always seeds the new `effectState` with `tpl.MaxDistance` unless a `range` field exists, so any partially-travelled projectile suddenly regains its full range. Players would see projectiles “reset” and travel much farther after resyncs, breaking determinism for long-lived shots. 【F:server/effects.go†L698-L762】【F:server/effects_manager.go†L616-L636】

## 2. Recreated projectiles ignore their remaining lifetime
- **File(s):** `server/effects.go`
- **Code:** `spawnContractProjectileFromInstance` derives the new `effectState.expiresAt` from `effectLifetime(tpl)` instead of the `EffectInstance.BehaviorState.TicksRemaining` that was tracked by the contract.
- **Why it’s a problem:** Contract instances decrement `TicksRemaining` every tick. If a projectile effect needs to be recreated (missing from `worldEffects`, journal replay, etc.), the helper should respect the remaining ticks. Instead it always resets to the template’s full lifetime, so resurrected projectiles linger much longer than intended and can double-hit targets after a resync. 【F:server/effects.go†L698-L747】【F:server/effects_manager.go†L330-L356】

## 3. State marshalling can drop data on serialization failures
- **File(s):** `server/hub.go`
- **Code:** `marshalState` drains the patch journal and effect event buffers (`drainPatchesLocked`, `DrainEffectEvents`) before attempting `json.Marshal`.
- **Why it’s a problem:** If `json.Marshal` fails (e.g. due to a NaN sneaking into a payload), `broadcastState` logs the error and returns, but the drained patches/effect events are already gone. The next broadcast has no way to resend them, so clients permanently miss those mutations and desync until the next keyframe. We should only drain buffers after a successful encode or requeue them on error. 【F:server/hub.go†L954-L1150】

## 4. Command queue accepts unbounded traffic from a single client
- **File(s):** `server/hub.go`
- **Code:** The hub exposes `enqueueCommand` and the HTTP/WebSocket handlers call it directly; the only safeguard is a log when `pendingCommands` crosses multiples of 256.
- **Why it’s a problem:** A misbehaving or malicious client can spam movement/path commands within one tick. Because there’s no per-player throttling or global cap, the slice can grow without limit, blowing up latency or exhausting memory before the next simulation step drains it. The warning log doesn’t prevent the denial-of-service. We need hard limits or drop policies per player. 【F:server/hub.go†L33-L59】【F:server/hub.go†L1094-L1113】
